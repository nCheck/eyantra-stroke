{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Smoking Status(Train) in  13292\n",
      "Empty Smoking Status(Test) in  5751\n",
      "Imbalance in train is  0    29470\n",
      "1      638\n",
      "Name: stroke, dtype: int64\n",
      "Imbalance in test is  0    9443\n",
      "1    3407\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "testY = pd.read_csv(\"output.csv\")\n",
    "testData['stroke'] = testY['stroke']\n",
    "trainData = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#Filling Missing BMI Data === train\n",
    "\n",
    "temp = trainData['bmi'].mean() + trainData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "trainData['bmi'] = trainData['bmi'].fillna(temp)\n",
    "\n",
    "#Filling Missing BMI Data ===test\n",
    "\n",
    "temp = testData['bmi'].mean() + testData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "testData['bmi'] = testData['bmi'].fillna(temp)\n",
    "\n",
    "print( \"Empty Smoking Status(Train) in \" , \n",
    "     len( list( filter( lambda x: x == True , pd.isna(trainData['smoking_status']) ) ) )\n",
    "     )\n",
    "\n",
    "\n",
    "print( \"Empty Smoking Status(Test) in \" , \n",
    "     len( list( filter( lambda x: x == True , pd.isna(testData['smoking_status']) ) ) )\n",
    "     )\n",
    "\n",
    "# Segregating into Two Models\n",
    "\n",
    "trainDataNS = trainData[ trainData['smoking_status'].isna() ]\n",
    "trainDataNS = trainDataNS.drop( columns=['smoking_status'] )\n",
    "trainDataS = trainData[ trainData['smoking_status'].notna() ]\n",
    "\n",
    "testDataNS = testData[ testData['smoking_status'].isna() ]\n",
    "testDataNS = testDataNS.drop( columns=['smoking_status'] )\n",
    "testDataS = testData[ testData['smoking_status'].notna() ]\n",
    "\n",
    "print( \"Imbalance in train is \", trainDataS['stroke'].value_counts() )\n",
    "print( \"Imbalance in test is \", testDataS['stroke'].value_counts() )\n",
    "\n",
    "# X and Y division\n",
    "\n",
    "yTrainDataNS = trainDataNS['stroke']\n",
    "xTrainDataNS = trainDataNS.drop( columns=['stroke'] )\n",
    "\n",
    "yTrainDataS = trainDataS['stroke']\n",
    "xTrainDataS = trainDataS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataNS = testDataNS['stroke']\n",
    "xTestDataNS = testDataNS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataS = testDataS['stroke']\n",
    "xTestDataS = testDataS.drop( columns=['stroke'] )\n",
    "\n",
    "#Nominal Categories to one-hot encoding === Train\n",
    "\n",
    "#Smoke Data\n",
    "xTrainDataS = pd.get_dummies( xTrainDataS, \n",
    "                             columns=['gender', 'ever_married', 'work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix=['sex', 'married', 'work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#No Smoke Data\n",
    "xTrainDataNS = pd.get_dummies( xTrainDataNS,\n",
    "                              columns=['gender', 'ever_married', 'work_type' , 'Residence_type']\n",
    "                            , prefix=['sex', 'married', 'work_type' , 'res_type'] )\n",
    "\n",
    "\n",
    "\n",
    "#Nominal Categories to one-hot encoding ===Test\n",
    "\n",
    "#Smoke Data\n",
    "xTestDataS = pd.get_dummies( xTestDataS,\n",
    "                            columns=['gender', 'ever_married', 'work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix=['sex', 'married', 'work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#No Smoke Data\n",
    "xTestDataNS = pd.get_dummies( xTestDataNS,\n",
    "                             columns=['gender', 'ever_married', 'work_type' , 'Residence_type']\n",
    "                            , prefix=['sex', 'married', 'work_type' , 'res_type'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "lr = LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Check Counter({0: 13147, 1: 145})\n",
      "1st Check Counter({0: 4207, 1: 1544})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "#sm=SMOTE()\n",
    "print(\"1st Check\",Counter(yTrainDataNS))\n",
    "print(\"1st Check\",Counter(yTestDataNS))\n",
    "#sm_x,sm_y=sm.fit_sample(xTrainDataNS,yTrainDataNS)\n",
    "#print(\"1st Check\",Counter(sm_y))\n",
    "#x_train, x_test, y_train, y_test = train_test_split(sm_x,sm_y, test_size=0, random_state=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(xTestDataNS,yTestDataNS, test_size=0, random_state=0)\n",
    "\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9890159494432742\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_test=yTrainDataNS\n",
    "x_test=xTrainDataNS\n",
    "predictions = lr.predict(x_test)\n",
    "predictions_Tree=clf.predict(x_test)\n",
    "\n",
    "print(lr.score(x_test, y_test))\n",
    "print(clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3410  797]\n",
      " [1219  325]]\n",
      "[[4160   47]\n",
      " [1518   26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "print(metrics.confusion_matrix(y_test,predictions_Tree))\n",
    "#MCC is better metric along with F-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023536443019994725"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic \n",
    "metrics.matthews_corrcoef(y_test, predictions, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02243592501341416"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tree\n",
    "metrics.matthews_corrcoef(y_test, predictions_Tree, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24381095273818457"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic\n",
    "metrics.f1_score(y_test, predictions, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032158317872603585"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tree\n",
    "metrics.f1_score(y_test, predictions_Tree, labels=None, pos_label=1, average='binary', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataS.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
