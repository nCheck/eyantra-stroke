{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "testY = pd.read_csv(\"output.csv\")\n",
    "testData['stroke'] = testY['stroke']\n",
    "trainData = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#Not Significant for Strokes\n",
    "\n",
    "trainData = trainData.drop( columns=['ever_married', 'gender', 'id','avg_glucose_level'] )\n",
    "testData = testData.drop( columns=['ever_married', 'gender', 'id','avg_glucose_level'] )\n",
    "\n",
    "#Filling Missing BMI Data === train\n",
    "\n",
    "temp = trainData['bmi'].mean() + trainData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "trainData['bmi'] = trainData['bmi'].fillna(temp)\n",
    "\n",
    "#Filling Missing BMI Data ===test\n",
    "\n",
    "temp = testData['bmi'].mean() + testData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "testData['bmi'] = testData['bmi'].fillna(temp)\n",
    "\n",
    "# Segregating into Two Models Smoking & Non-Smoking\n",
    "\n",
    "trainDataNS = trainData[ trainData['smoking_status'].isna() ]\n",
    "trainDataNS = trainDataNS.drop( columns=['smoking_status'] )\n",
    "trainDataS = trainData[ trainData['smoking_status'].notna() ]\n",
    "\n",
    "testDataNS = testData[ testData['smoking_status'].isna() ]\n",
    "testDataNS = testDataNS.drop( columns=['smoking_status'] )\n",
    "testDataS = testData[ testData['smoking_status'].notna() ]\n",
    "\n",
    "# X and Y division\n",
    "\n",
    "yTrainDataNS = trainDataNS['stroke']\n",
    "xTrainDataNS = trainDataNS.drop( columns=['stroke'] )\n",
    "\n",
    "yTrainDataS = trainDataS['stroke']\n",
    "xTrainDataS = trainDataS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataNS = testDataNS['stroke']\n",
    "xTestDataNS = testDataNS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataS = testDataS['stroke']\n",
    "xTestDataS = testDataS.drop( columns=['stroke'] )\n",
    "\n",
    "#Nominal Categories to one-hot encoding === Train\n",
    "\n",
    "#Smoke Data\n",
    "xTrainDataS = pd.get_dummies( xTrainDataS, \n",
    "                             columns=[ 'work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix= ['work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#No Smoke Data\n",
    "xTrainDataNS = pd.get_dummies( xTrainDataNS,\n",
    "                              columns=[ 'work_type' , 'Residence_type']\n",
    "                            , prefix=['work_type' , 'res_type'] )\n",
    "\n",
    "#Nominal Categories to one-hot encoding ===Test\n",
    "\n",
    "#Smoke Data\n",
    "xTestDataS = pd.get_dummies( xTestDataS,\n",
    "                            columns=['work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix=['work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#No Smoke Data\n",
    "xTestDataNS = pd.get_dummies( xTestDataNS,\n",
    "                             columns=['work_type' , 'Residence_type']\n",
    "                            , prefix=['work_type' , 'res_type'] )\n",
    "\n",
    "smokeCol = xTrainDataS.columns\n",
    "nsmokeCol = xTrainDataNS.columns\n",
    "\n",
    "\n",
    "#Sampling for removing imbalance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "smote = RandomOverSampler(random_state=0)\n",
    "\n",
    "xTrainDataNS, yTrainDataNS = smote.fit_sample(xTrainDataNS, yTrainDataNS)\n",
    "xTrainDataS, yTrainDataS = smote.fit_sample(xTrainDataS, yTrainDataS)\n",
    "\n",
    "xTrainDataS = pd.DataFrame( xTrainDataS , columns=smokeCol )\n",
    "xTrainDataNS = pd.DataFrame( xTrainDataNS , columns=nsmokeCol )\n",
    "yTrainDataS = pd.DataFrame( yTrainDataS , columns=['stroke'])\n",
    "yTrainDataNS = pd.DataFrame( yTrainDataNS , columns=['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Train Splitter\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xTrainDataNS, np.ravel( yTrainDataNS , order='C' ) \n",
    "                                                    , test_size=0.35, random_state=0)\n",
    "\n",
    "x_trainS, x_testS, y_trainS, y_testS = train_test_split(xTrainDataS, np.ravel( yTrainDataS , order='C' ),\n",
    "                                                        test_size=0.35, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "xTestDataNS = scaler.transform( xTestDataNS )\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_trainS)\n",
    "\n",
    "x_trainS = scaler.transform(x_trainS)\n",
    "x_testS = scaler.transform(x_testS)\n",
    "xTestDataS = scaler.transform( xTestDataS )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9208395947452616\n",
      "[[ 8687  1581]\n",
      " [   52 10309]]\n",
      "0.6601556420233463\n",
      "[[7998 1445]\n",
      " [2922  485]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n \\n0.00008 \\n \\n0.9163313781569635\\n[[ 8891  1377]\\n [  349 10012]]\\n0.6646692607003891\\n[[8121 1322]\\n [2987  420]]\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "sModel = MLPClassifier( hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.00008 )\n",
    "\n",
    "\n",
    "sModel.fit(x_trainS, y_trainS)\n",
    "\n",
    "\n",
    "#Synthetic Test\n",
    "\n",
    "predictions = sModel.predict(x_testS)\n",
    "print(sModel.score(x_testS, y_testS))\n",
    "print(metrics.confusion_matrix(y_testS, predictions))\n",
    "\n",
    "\n",
    "#Blind Test\n",
    "\n",
    "predictions = sModel.predict(xTestDataS)\n",
    "print(sModel.score(xTestDataS, yTestDataS))\n",
    "print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "\n",
    "\"\"\"\n",
    " \n",
    "0.9208395947452616\n",
    "[[ 8687  1581]\n",
    " [   52 10309]]\n",
    "0.6601556420233463\n",
    "[[7998 1445]\n",
    " [2922  485]]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smokemlp.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates Model for Flask running\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "dump( sModel , 'smokemlp.joblib' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225578615668804\n",
      "[[3537 1041]\n",
      " [ 592 4033]]\n",
      "0.6338028169014085\n",
      "[[3265  942]\n",
      " [1164  380]]\n"
     ]
    }
   ],
   "source": [
    "######## No Smoke Data - mlp didnt work\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.RidgeClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Synthetic DataTest\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "#BlindTest\n",
    "\n",
    "predictions = model.predict(xTestDataNS)\n",
    "print(model.score(xTestDataNS, yTestDataNS))\n",
    "print(metrics.confusion_matrix(yTestDataNS, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump( model , 'nosmokemlp.joblib' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
