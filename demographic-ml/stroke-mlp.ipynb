{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "testY = pd.read_csv(\"output.csv\")\n",
    "testData['stroke'] = testY['stroke']\n",
    "trainData = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#Not Significant for Strokes\n",
    "\n",
    "trainData = trainData.drop( columns=['ever_married', 'gender', 'id','avg_glucose_level'] )\n",
    "testData = testData.drop( columns=['ever_married', 'gender', 'id','avg_glucose_level'] )\n",
    "\n",
    "#Filling Missing BMI Data === train\n",
    "\n",
    "temp = trainData['bmi'].mean() + trainData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "trainData['bmi'] = trainData['bmi'].fillna(temp)\n",
    "\n",
    "#Filling Missing BMI Data ===test\n",
    "\n",
    "temp = testData['bmi'].mean() + testData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "testData['bmi'] = testData['bmi'].fillna(temp)\n",
    "\n",
    "# Segregating into Two Models Smoking & Non-Smoking\n",
    "\n",
    "trainDataNS = trainData[ trainData['smoking_status'].isna() ]\n",
    "trainDataNS = trainDataNS.drop( columns=['smoking_status'] )\n",
    "trainDataS = trainData[ trainData['smoking_status'].notna() ]\n",
    "\n",
    "testDataNS = testData[ testData['smoking_status'].isna() ]\n",
    "testDataNS = testDataNS.drop( columns=['smoking_status'] )\n",
    "testDataS = testData[ testData['smoking_status'].notna() ]\n",
    "\n",
    "# X and Y division\n",
    "\n",
    "yTrainDataNS = trainDataNS['stroke']\n",
    "xTrainDataNS = trainDataNS.drop( columns=['stroke'] )\n",
    "\n",
    "yTrainDataS = trainDataS['stroke']\n",
    "xTrainDataS = trainDataS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataNS = testDataNS['stroke']\n",
    "xTestDataNS = testDataNS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataS = testDataS['stroke']\n",
    "xTestDataS = testDataS.drop( columns=['stroke'] )\n",
    "\n",
    "#Nominal Categories to one-hot encoding === Train\n",
    "\n",
    "#Smoke Data\n",
    "xTrainDataS = pd.get_dummies( xTrainDataS, \n",
    "                             columns=[ 'work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix= ['work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#No Smoke Data\n",
    "xTrainDataNS = pd.get_dummies( xTrainDataNS,\n",
    "                              columns=[ 'work_type' , 'Residence_type']\n",
    "                            , prefix=['[work_type' , 'res_type'] )\n",
    "\n",
    "#Nominal Categories to one-hot encoding ===Test\n",
    "\n",
    "#Smoke Data\n",
    "xTestDataS = pd.get_dummies( xTestDataS,\n",
    "                            columns=['work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix=['work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#No Smoke Data\n",
    "xTestDataNS = pd.get_dummies( xTestDataNS,\n",
    "                             columns=['work_type' , 'Residence_type']\n",
    "                            , prefix=['work_type' , 'res_type'] )\n",
    "\n",
    "smokeCol = xTrainDataS.columns\n",
    "nsmokeCol = xTrainDataNS.columns\n",
    "\n",
    "\n",
    "#Sampling for removing imbalance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "xTrainDataNS, yTrainDataNS = smote.fit_sample(xTrainDataNS, yTrainDataNS)\n",
    "xTrainDataS, yTrainDataS = smote.fit_sample(xTrainDataS, yTrainDataS)\n",
    "\n",
    "xTrainDataS = pd.DataFrame( xTrainDataS , columns=smokeCol )\n",
    "xTrainDataNS = pd.DataFrame( xTrainDataNS , columns=nsmokeCol )\n",
    "yTrainDataS = pd.DataFrame( yTrainDataS , columns=['stroke'])\n",
    "yTrainDataNS = pd.DataFrame( yTrainDataNS , columns=['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'hypertension', 'heart_disease', 'bmi', '[work_type_Govt_job',\n",
       "       '[work_type_Never_worked', '[work_type_Private',\n",
       "       '[work_type_Self-employed', '[work_type_children', 'res_type_Rural',\n",
       "       'res_type_Urban'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainDataNS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>[work_type_Govt_job</th>\n",
       "      <th>[work_type_Never_worked</th>\n",
       "      <th>[work_type_Private</th>\n",
       "      <th>[work_type_Self-employed</th>\n",
       "      <th>[work_type_children</th>\n",
       "      <th>res_type_Rural</th>\n",
       "      <th>res_type_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26289</th>\n",
       "      <td>58.216043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.168777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26290</th>\n",
       "      <td>59.439218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.319609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560782</td>\n",
       "      <td>0.439218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26291</th>\n",
       "      <td>80.520617</td>\n",
       "      <td>0.520617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.471137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26292</th>\n",
       "      <td>57.455395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544605</td>\n",
       "      <td>28.152519</td>\n",
       "      <td>0.544605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>78.934323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.640891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065677</td>\n",
       "      <td>0.934323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease        bmi  [work_type_Govt_job  \\\n",
       "26289  58.216043      0.000000       0.000000  31.168777             0.000000   \n",
       "26290  59.439218      0.000000       0.000000  44.319609             0.000000   \n",
       "26291  80.520617      0.520617       1.000000  23.471137             0.000000   \n",
       "26292  57.455395      0.000000       0.544605  28.152519             0.544605   \n",
       "26293  78.934323      0.000000       1.000000  30.640891             0.000000   \n",
       "\n",
       "       [work_type_Never_worked  [work_type_Private  [work_type_Self-employed  \\\n",
       "26289                      0.0            1.000000                       0.0   \n",
       "26290                      0.0            1.000000                       0.0   \n",
       "26291                      0.0            0.000000                       1.0   \n",
       "26292                      0.0            0.455395                       0.0   \n",
       "26293                      0.0            0.000000                       1.0   \n",
       "\n",
       "       [work_type_children  res_type_Rural  res_type_Urban  \n",
       "26289                  0.0        1.000000        0.000000  \n",
       "26290                  0.0        0.560782        0.439218  \n",
       "26291                  0.0        0.000000        1.000000  \n",
       "26292                  0.0        0.000000        1.000000  \n",
       "26293                  0.0        0.065677        0.934323  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainDataNS.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Train Splitter\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xTrainDataNS, np.ravel( yTrainDataNS , order='C' ) \n",
    "                                                    , test_size=0.30, random_state=0)\n",
    "\n",
    "x_trainS, x_testS, y_trainS, y_testS = train_test_split(xTrainDataS, np.ravel( yTrainDataS , order='C' ),\n",
    "                                                        test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncheck/anaconda3/envs/deepenv/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/home/ncheck/anaconda3/envs/deepenv/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "xTestDataNS = scaler.transform( xTestDataNS )\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_trainS)\n",
    "\n",
    "x_trainS = scaler.transform(x_trainS)\n",
    "x_testS = scaler.transform(x_testS)\n",
    "xTestDataS = scaler.transform( xTestDataS )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938355389661803\n",
      "[[8231  549]\n",
      " [ 541 8361]]\n",
      "0.701556420233463\n",
      "[[8818  625]\n",
      " [3210  197]]\n",
      "************* 4e-05\n",
      "0.9357538739961543\n",
      "[[8308  472]\n",
      " [ 664 8238]]\n",
      "0.705603112840467\n",
      "[[8911  532]\n",
      " [3251  156]]\n",
      "************* 6.000000000000001e-05\n",
      "0.9350186630471666\n",
      "[[8178  602]\n",
      " [ 547 8355]]\n",
      "0.7007003891050584\n",
      "[[8797  646]\n",
      " [3200  207]]\n",
      "************* 8e-05\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "alpha=0.00002\n",
    "for i in range(18):\n",
    "    \n",
    "    alpha += 0.00002\n",
    "    sModel = MLPClassifier( hidden_layer_sizes=(64,64,64) , max_iter=300 , alpha=alpha  )\n",
    "\n",
    "\n",
    "    sModel.fit(x_trainS, y_trainS)\n",
    "\n",
    "\n",
    "    predictions = sModel.predict(x_testS)\n",
    "\n",
    "    print(sModel.score(x_testS, y_testS))\n",
    "    print(metrics.confusion_matrix(y_testS, predictions))\n",
    "\n",
    "\n",
    "    #Blind Test\n",
    "\n",
    "    predictions = sModel.predict(xTestDataS)\n",
    "\n",
    "\n",
    "    print(sModel.score(xTestDataS, yTestDataS))\n",
    "    print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "    \n",
    "    print(\"*************\", alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "0.7962576954772408\n",
    "[[7369 2899]\n",
    " [1304 9057]]\n",
    "0.5964980544747082\n",
    "[[6704 2739]\n",
    " [2446  961]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64,64) , max_iter=300 , alpha=0.00015 \n",
    "\n",
    "0.9261234184885355\n",
    "[[ 8849  1419]\n",
    " [  105 10256]]\n",
    "0.6644357976653696\n",
    "[[8089 1354]\n",
    " [2958  449]]\n",
    "\n",
    "$ dropped glucose hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.00015\n",
    "\n",
    "0.8628144844636192\n",
    "[[8092 2176]\n",
    " [ 654 9707]]\n",
    "0.6327626459143969\n",
    "[[7447 1996]\n",
    " [2723  684]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.0003\n",
    "\n",
    "0.8783266275631393\n",
    "[[ 8073  2195]\n",
    " [  315 10046]]\n",
    "0.6292607003891051\n",
    "[[7398 2045]\n",
    " [2719  688]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.0006\n",
    "\n",
    "0.8612632701536672\n",
    "[[7882 2386]\n",
    " [ 476 9885]]\n",
    "0.6214007782101167\n",
    "[[7214 2229]\n",
    " [2636  771]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.0006 scaled\n",
    "\n",
    "0.9007222841630714\n",
    "[[9067 1201]\n",
    " [ 847 9514]]\n",
    "0.674863813229572\n",
    "[[8312 1131]\n",
    " [3047  360]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.0001 scaled\n",
    "\n",
    "0.9171069853119395\n",
    "[[ 8657  1611]\n",
    " [   99 10262]]\n",
    "0.6598443579766538\n",
    "[[7974 1469]\n",
    " [2902  505]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.00005 scaled\n",
    "\n",
    "0.9002375296912114\n",
    "[[ 8299  1969]\n",
    " [   89 10272]]\n",
    "0.6368093385214008\n",
    "[[7576 1867]\n",
    " [2800  607]]\n",
    "\n",
    "$ hidden_layer_sizes=(16,64,64) , max_iter=300 , alpha=0.00005  smote\n",
    "\n",
    "0.9247257097613392\n",
    "[[8210  570]\n",
    " [ 761 8141]]\n",
    "0.7001556420233463\n",
    "[[8789  654]\n",
    " [3199  208]]\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smokemlp.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump( sModel , 'smokemlp.joblib' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876453330435727\n",
      "[[3606  972]\n",
      " [  62 4563]]\n",
      "0.6395409494001043\n",
      "[[3340  867]\n",
      " [1206  338]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MLPClassifier(alpha=0.0002, max_iter=400 )\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "predictions = model.predict(xTestDataNS)\n",
    "\n",
    "\n",
    "print(model.score(xTestDataNS, yTestDataNS))\n",
    "print(metrics.confusion_matrix(yTestDataNS, predictions))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "0.8876453330435727\n",
    "[[3606  972]\n",
    " [  62 4563]]\n",
    "0.6395409494001043\n",
    "[[3340  867]\n",
    " [1206  338]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nosmokemlp.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump( model , 'nosmokemlp.joblib' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 8902, 0: 8780})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(y_testS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
