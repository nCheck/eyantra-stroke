{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Name: AI Based Early Stroke Detection \n",
    "# Author List: Nehal Kalnad,Ashley Lobo, e-Yantra Team \n",
    "# Filename: neural-network.ipynb\n",
    "# Functions: imblearn.over_sampling.smote.fit_sample ,sklearn.preprocessing.StandardScaler, sklearn.neural_network.MLPClassifier.predict\n",
    "# Global Variables:testData,testY,trainData,temp,scaler,trainDataNS,trainDataS,testDataNS,testDataS,xTrainDataNS,yTrainDataNS,model,predictions, \n",
    "#                  xTrainDataS,yTrainDataS,smokeCol,nsmokeCol,x_train,x_test,y_train,y_test,x_trainS,x_testS,y_trainS,y_testS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "# Data set obtained from\n",
    "# https://www.kaggle.com/asaumya/healthcare-dataset-stroke-data\n",
    "\n",
    "testData = pd.read_csv(\"data/test.csv\")\n",
    "testY = pd.read_csv(\"data/output.csv\")\n",
    "testData['stroke'] = testY['stroke']\n",
    "trainData = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "#Not Significant for Strokes\n",
    "\n",
    "trainData = trainData.drop( columns=['ever_married', 'gender', 'id','avg_glucose_level'] )\n",
    "testData = testData.drop( columns=['ever_married', 'gender', 'id','avg_glucose_level'] )\n",
    "\n",
    "#Filling Missing BMI Data === train\n",
    "\n",
    "temp = trainData['bmi'].mean() + trainData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "trainData['bmi'] = trainData['bmi'].fillna(temp)\n",
    "\n",
    "#Filling Missing BMI Data ===test\n",
    "\n",
    "temp = testData['bmi'].mean() + testData['bmi'].median()\n",
    "temp /= 2\n",
    "temp\n",
    "testData['bmi'] = testData['bmi'].fillna(temp)\n",
    "\n",
    "# Segregating into Two Models Smoking & Non-Smoking\n",
    "\n",
    "\n",
    "trainDataS = trainData[ trainData['smoking_status'].notna() ]\n",
    "testDataS = testData[ testData['smoking_status'].notna() ]\n",
    "\n",
    "# X and Y division\n",
    "\n",
    "yTrainDataS = trainDataS['stroke']\n",
    "xTrainDataS = trainDataS.drop( columns=['stroke'] )\n",
    "\n",
    "yTestDataS = testDataS['stroke']\n",
    "xTestDataS = testDataS.drop( columns=['stroke'] )\n",
    "\n",
    "#Nominal Categories to one-hot encoding === Train\n",
    "\n",
    "#Smoke Data\n",
    "xTrainDataS = pd.get_dummies( xTrainDataS, \n",
    "                             columns=[ 'work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix= ['work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "#Nominal Categories to one-hot encoding ===Test\n",
    "\n",
    "#Smoke Data\n",
    "xTestDataS = pd.get_dummies( xTestDataS,\n",
    "                            columns=['work_type' , 'Residence_type', 'smoking_status']\n",
    "                            , prefix=['work_type' , 'res_type', 'smoke'] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "smokeCol = xTrainDataS.columns\n",
    "# nsmokeCol = xTrainDataNS.columns\n",
    "\n",
    "\n",
    "#Sampling for removing imbalance\n",
    "\n",
    "\n",
    "# Function Name:imblearn.over_sampling.smote.fit_sample \n",
    "# Input:X:{array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "#               y:array-like, shape (n_samples,) \n",
    "# Output:X_resampled:{array-like, sparse matrix}, shape (n_samples_new, n_features) \n",
    "#               y_resampled:array-like, shape (n_samples_new,) \n",
    "# Logic:Used to balance dataset\n",
    "# Example Call: X_res, y_res = sm.fit_sample(X, y) \n",
    "\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "smote = RandomOverSampler(random_state=0)\n",
    "\n",
    "\n",
    "xTrainDataS, yTrainDataS = smote.fit_sample(xTrainDataS, yTrainDataS)\n",
    "\n",
    "xTrainDataS = pd.DataFrame( xTrainDataS , columns=smokeCol )\n",
    "yTrainDataS = pd.DataFrame( yTrainDataS , columns=['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Train Splitter\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xTrainDataS, np.ravel( yTrainDataS , order='C' ),\n",
    "                                                        test_size=0.35, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5184449076542731\n",
      "[[  334  9934]\n",
      " [    0 10361]]\n",
      "0.3145525291828794\n",
      "[[ 382 8807]\n",
      " [   1 3660]]\n",
      "=======\n",
      "0.45386904761904767\n",
      "0.3145525291828794\n",
      "0.29357503810058555\n"
     ]
    }
   ],
   "source": [
    "#Naive Base\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "#naiva base on test data\n",
    "\n",
    "predictions = model.predict(xTestDataS)\n",
    "\n",
    "\n",
    "print(model.score(xTestDataS, yTestDataS))\n",
    "print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "\n",
    "print(\"=======\")\n",
    "print(metrics.f1_score(yTestDataS, predictions))\n",
    "print(metrics.accuracy_score(yTestDataS, predictions))\n",
    "print(metrics.precision_score(yTestDataS, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7460371321925445\n",
      "[[7277 2991]\n",
      " [2248 8113]]\n",
      "0.9592217898832684\n",
      "[[8825  364]\n",
      " [ 160 3501]]\n",
      "=======\n",
      "0.9303747010364072\n",
      "0.9592217898832684\n",
      "0.9058214747736093\n"
     ]
    }
   ],
   "source": [
    "## RidgeClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.RidgeClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "## Blindtest\n",
    "\n",
    "predictions = model.predict(xTestDataS)\n",
    "\n",
    "print(model.score(xTestDataS, yTestDataS))\n",
    "print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "\n",
    "\n",
    "print(\"=======\")\n",
    "print(metrics.f1_score(yTestDataS, predictions))\n",
    "print(metrics.accuracy_score(yTestDataS, predictions))\n",
    "print(metrics.precision_score(yTestDataS, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncheck/anaconda3/envs/deepenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458432304038005\n",
      "[[7436 2832]\n",
      " [2411 7950]]\n",
      "0.966614785992218\n",
      "[[8968  221]\n",
      " [ 208 3453]]\n",
      "=======\n",
      "0.9415132924335378\n",
      "0.966614785992218\n",
      "0.9398475775721284\n"
     ]
    }
   ],
   "source": [
    "#Logistic Reg =====Best\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "model = LR()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "#LR on Test\n",
    "\n",
    "predictions = model.predict(xTestDataS)\n",
    "\n",
    "\n",
    "print(model.score(xTestDataS, yTestDataS))\n",
    "print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "\n",
    "\n",
    "print(\"=======\")\n",
    "print(metrics.f1_score(yTestDataS, predictions))\n",
    "print(metrics.accuracy_score(yTestDataS, predictions))\n",
    "print(metrics.precision_score(yTestDataS, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regmodel.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib as jl \n",
    "jl.dump(model, 'regmodel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9837607251926899\n",
      "[[ 9933   335]\n",
      " [    0 10361]]\n",
      "0.7322178988326848\n",
      "[[9103   86]\n",
      " [3355  306]]\n",
      "=======\n",
      "0.15099925980754997\n",
      "0.7322178988326848\n",
      "0.7806122448979592\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "#LR on Test\n",
    "\n",
    "predictions = model.predict(xTestDataS)\n",
    "\n",
    "\n",
    "print(model.score(xTestDataS, yTestDataS))\n",
    "print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "\n",
    "\n",
    "print(\"=======\")\n",
    "print(metrics.f1_score(yTestDataS, predictions))\n",
    "print(metrics.accuracy_score(yTestDataS, predictions))\n",
    "print(metrics.precision_score(yTestDataS, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncheck/anaconda3/envs/deepenv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8668864220272432\n",
      "[[7972 2296]\n",
      " [ 450 9911]]\n",
      "0.8309727626459144\n",
      "[[8462  727]\n",
      " [1445 2216]]\n",
      "=======\n",
      "0.6711084191399151\n",
      "0.8309727626459144\n",
      "0.7529731566428814\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(metrics.confusion_matrix(y_test, predictions))\n",
    "\n",
    "#LR on Test\n",
    "\n",
    "predictions = model.predict(xTestDataS)\n",
    "\n",
    "\n",
    "print(model.score(xTestDataS, yTestDataS))\n",
    "print(metrics.confusion_matrix(yTestDataS, predictions))\n",
    "\n",
    "\n",
    "print(\"=======\")\n",
    "print(metrics.f1_score(yTestDataS, predictions))\n",
    "print(metrics.accuracy_score(yTestDataS, predictions))\n",
    "print(metrics.precision_score(yTestDataS, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
